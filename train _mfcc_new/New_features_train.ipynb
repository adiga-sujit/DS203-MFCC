{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from scipy import stats, signal\n",
    "import pandas as pd\n",
    "from scipy.fft import fft\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_enhanced_mfcc_features(mfcc_matrix):\n",
    "    \"\"\"\n",
    "    Extract enhanced features from MFCC coefficients matrix, specifically designed\n",
    "    for music and voice classification.\n",
    "    \n",
    "    Parameters:\n",
    "    mfcc_matrix: numpy array of shape (20, n_timestamps)\n",
    "        The MFCC coefficients matrix\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary containing extracted features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # 1. Basic Statistical Features (from previous code)\n",
    "    for i in range(20):\n",
    "        coeff = mfcc_matrix[i, :]\n",
    "        \n",
    "        # Calculate first-order deltas (velocity)\n",
    "        delta = librosa.feature.delta(coeff.reshape(1, -1), width=19)\n",
    "        \n",
    "        # Calculate second-order deltas (acceleration)\n",
    "        delta_delta = librosa.feature.delta(delta, order=2, width=19)\n",
    "        \n",
    "        # Basic statistics for original coefficients\n",
    "        features[f'mfcc{i}_mean'] = np.mean(coeff)\n",
    "        features[f'mfcc{i}_std'] = np.std(coeff)\n",
    "        features[f'mfcc{i}_median'] = np.median(coeff)\n",
    "        \n",
    "        # Statistics for deltas (velocity features)\n",
    "        features[f'mfcc{i}_delta_mean'] = np.mean(delta)\n",
    "        features[f'mfcc{i}_delta_std'] = np.std(delta)\n",
    "        features[f'mfcc{i}_delta_max'] = np.max(np.abs(delta))\n",
    "        \n",
    "        # Statistics for delta-deltas (acceleration features)\n",
    "        features[f'mfcc{i}_delta2_mean'] = np.mean(delta_delta)\n",
    "        features[f'mfcc{i}_delta2_std'] = np.std(delta_delta)\n",
    "        features[f'mfcc{i}_delta2_max'] = np.max(np.abs(delta_delta))\n",
    "        \n",
    "        # Temporal variation features\n",
    "        features[f'mfcc{i}_delta_zero_crossings'] = np.sum(np.diff(np.signbit(delta)))\n",
    "        features[f'mfcc{i}_delta2_zero_crossings'] = np.sum(np.diff(np.signbit(delta_delta)))\n",
    "        \n",
    "        # Energy-related features\n",
    "        features[f'mfcc{i}_delta_energy'] = np.sum(delta ** 2)\n",
    "        features[f'mfcc{i}_delta2_energy'] = np.sum(delta_delta ** 2)\n",
    "        \n",
    "        # Ratio features\n",
    "        features[f'mfcc{i}_delta_energy_ratio'] = features[f'mfcc{i}_delta_energy'] / np.sum(coeff ** 2)\n",
    "        features[f'mfcc{i}_delta2_energy_ratio'] = features[f'mfcc{i}_delta2_energy'] / features[f'mfcc{i}_delta_energy']\n",
    "\n",
    "    # 2. Rhythm-based Features\n",
    "    for i in range(20):\n",
    "        coeff = mfcc_matrix[i, :]\n",
    "        \n",
    "        # Detect peaks in the coefficient\n",
    "        peaks, _ = signal.find_peaks(coeff)\n",
    "        if len(peaks) > 1:\n",
    "            # Average distance between peaks (rhythm indicator)\n",
    "            features[f'mfcc{i}_peak_distance_mean'] = np.mean(np.diff(peaks))\n",
    "            features[f'mfcc{i}_peak_distance_std'] = np.std(np.diff(peaks))\n",
    "        else:\n",
    "            features[f'mfcc{i}_peak_distance_mean'] = 0\n",
    "            features[f'mfcc{i}_peak_distance_std'] = 0\n",
    "        \n",
    "        # Number of peaks normalized by length\n",
    "        features[f'mfcc{i}_peak_density'] = len(peaks) / len(coeff)\n",
    "    \n",
    "    # 3. Spectral Features\n",
    "    for i in range(20):\n",
    "        coeff = mfcc_matrix[i, :]\n",
    "        \n",
    "        # FFT for frequency analysis\n",
    "        fft_vals = np.abs(fft(coeff))\n",
    "        \n",
    "        # Spectral centroid (brightness of sound)\n",
    "        freqs = np.fft.fftfreq(len(coeff))\n",
    "        features[f'mfcc{i}_spectral_centroid'] = np.sum(freqs * fft_vals) / np.sum(fft_vals)\n",
    "        \n",
    "        # Spectral rolloff (shape of spectrum)\n",
    "        cumsum = np.cumsum(fft_vals)\n",
    "        rolloff_point = np.where(cumsum >= 0.85 * cumsum[-1])[0][0]\n",
    "        features[f'mfcc{i}_spectral_rolloff'] = rolloff_point / len(fft_vals)\n",
    "    \n",
    "    # 4. Temporal Segmentation Features\n",
    "    segment_size = mfcc_matrix.shape[1] // 3  # Split into three segments\n",
    "    \n",
    "    for i in range(20):\n",
    "        coeff = mfcc_matrix[i, :]\n",
    "        \n",
    "        # Features for beginning, middle, and end of song\n",
    "        features[f'mfcc{i}_begin_mean'] = np.mean(coeff[:segment_size])\n",
    "        features[f'mfcc{i}_middle_mean'] = np.mean(coeff[segment_size:2*segment_size])\n",
    "        features[f'mfcc{i}_end_mean'] = np.mean(coeff[2*segment_size:])\n",
    "    \n",
    "    # 5. Cross-MFCC Dynamic Features\n",
    "    # Compute pairwise differences between consecutive frames\n",
    "    deltas = np.diff(mfcc_matrix, axis=1)\n",
    "    \n",
    "    # Overall dynamics\n",
    "    features['total_dynamics'] = np.mean(np.abs(deltas))\n",
    "    features['dynamics_std'] = np.std(deltas)\n",
    "    \n",
    "    # Compute acceleration (second-order differences)\n",
    "    accel = np.diff(deltas, axis=1)\n",
    "    features['total_acceleration'] = np.mean(np.abs(accel))\n",
    "    features['acceleration_std'] = np.std(accel)\n",
    "    \n",
    "    # 6. Structural Features\n",
    "    # Silence detection (low energy frames)\n",
    "    energy = np.sum(mfcc_matrix ** 2, axis=0)\n",
    "    silence_threshold = np.mean(energy) * 0.1\n",
    "    silence_frames = np.sum(energy < silence_threshold)\n",
    "    features['silence_ratio'] = silence_frames / len(energy)\n",
    "    \n",
    "    # Variation over time windows\n",
    "    window_size = min(100, mfcc_matrix.shape[1] // 10)\n",
    "    for i in range(0, 20, 4):  # Take every 4th coefficient to reduce dimensionality\n",
    "        coeff = mfcc_matrix[i, :]\n",
    "        windows = np.array_split(coeff, 10)  # Split into 10 windows\n",
    "        window_means = [np.mean(w) for w in windows]\n",
    "        features[f'mfcc{i}_temporal_variation'] = np.std(window_means)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def get_feature_importance(X, y, n_estimators=100):\n",
    "    \"\"\"\n",
    "    Train a Random Forest classifier and return feature importance\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Get feature importance\n",
    "    importance_dict = dict(zip(X.columns, rf.feature_importances_))\n",
    "    return dict(sorted(importance_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "def visualize_features(features_df, target_labels=None):\n",
    "    \"\"\"\n",
    "    Create visualizations of the features\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Select top numerical columns (exclude file_name and other non-numeric)\n",
    "    numeric_cols = features_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Create correlation heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(features_df[numeric_cols].corr(), cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if target_labels is not None:\n",
    "        # Box plots for top features by class\n",
    "        for col in numeric_cols[:5]:  # Plot top 5 features\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.boxplot(x=target_labels, y=features_df[col])\n",
    "            plt.title(f'{col} Distribution by Class')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = glob.glob('*.csv')\n",
    "features_df = pd.DataFrame([extract_enhanced_mfcc_features(pd.read_csv(f, header=None).values) \n",
    "                          for f in file_names])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_standardized = scaler.fit_transform(features_df)\n",
    "data_standardized_df = pd.DataFrame(data_standardized, columns=features_df.columns)\n",
    "data_standardized_df.to_csv(\"train_data_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
